{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sprint 3 Data Science Report\n",
        "## NFT Ticketing Platform - Fraud Detection Model Evaluation\n",
        "\n",
        "**Report Date**: 2025-11-28  \n",
        "**Model Version**: v1.2.3  \n",
        "**Platform Scale**: 50k-200k daily events\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preparation\n",
        "\n",
        "### Load and Explore Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data (if available, otherwise use sample)\n",
        "try:\n",
        "    df = pd.read_csv('../demos/data/sample_transactions.csv')\n",
        "except:\n",
        "    # Generate sample data\n",
        "    np.random.seed(42)\n",
        "    n = 1000\n",
        "    df = pd.DataFrame({\n",
        "        'transaction_id': [f'txn_{i:06d}' for i in range(n)],\n",
        "        'wallet_address': [f'0x{i%100:040x}' for i in range(n)],\n",
        "        'txn_velocity_1h': np.random.poisson(2, n),\n",
        "        'wallet_age_days': np.random.exponential(30, n),\n",
        "        'avg_ticket_hold_time': np.random.normal(48, 12, n),\n",
        "        'event_popularity_score': np.random.beta(2, 5, n),\n",
        "        'price_deviation_ratio': np.random.normal(0, 0.3, n),\n",
        "        'cross_event_attendance': np.random.poisson(2, n),\n",
        "        'geo_velocity_flag': np.random.binomial(1, 0.05, n),\n",
        "        'payment_method_diversity': np.random.poisson(1, n) + 1,\n",
        "        'social_graph_centrality': np.random.beta(1, 2, n),\n",
        "        'time_to_first_resale': np.random.exponential(720, n),\n",
        "        'is_fraud': (np.random.random(n) < 0.02).astype(int)\n",
        "    })\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Fraud rate: {df['is_fraud'].mean():.2%}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature List\n",
        "\n",
        "**10 Core Features:**\n",
        "1. `txn_velocity_1h` - Transaction velocity in 1 hour\n",
        "2. `wallet_age_days` - Wallet age in days\n",
        "3. `avg_ticket_hold_time` - Average ticket hold time\n",
        "4. `event_popularity_score` - Event popularity score\n",
        "5. `price_deviation_ratio` - Price deviation from floor\n",
        "6. `cross_event_attendance` - Cross-event attendance count\n",
        "7. `geo_velocity_flag` - Geographic velocity flag\n",
        "8. `payment_method_diversity` - Payment method diversity\n",
        "9. `social_graph_centrality` - Social graph centrality\n",
        "10. `time_to_first_resale` - Time to first resale (minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature statistics\n",
        "feature_cols = [\n",
        "    'txn_velocity_1h',\n",
        "    'wallet_age_days',\n",
        "    'avg_ticket_hold_time',\n",
        "    'event_popularity_score',\n",
        "    'price_deviation_ratio',\n",
        "    'cross_event_attendance',\n",
        "    'geo_velocity_flag',\n",
        "    'payment_method_diversity',\n",
        "    'social_graph_centrality',\n",
        "    'time_to_first_resale'\n",
        "]\n",
        "\n",
        "df[feature_cols].describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n",
        "\n",
        "### Prepare Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and target\n",
        "X = df[feature_cols].fillna(0)\n",
        "y = df['is_fraud'].astype(int)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Train fraud rate: {y_train.mean():.2%}\")\n",
        "print(f\"Test fraud rate: {y_test.mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost model\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "fraud_count = y_train.sum()\n",
        "legit_count = len(y_train) - fraud_count\n",
        "scale_pos_weight = legit_count / fraud_count if fraud_count > 0 else 1.0\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='aucpr',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print(\"âœ… Model training complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Performance Metrics\n",
        "\n",
        "### Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.65).astype(int)\n",
        "\n",
        "# Calculate metrics\n",
        "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "auc_pr = auc(recall, precision)\n",
        "\n",
        "print(f\"AUC-ROC: {auc_roc:.3f}\")\n",
        "print(f\"AUC-PR:  {auc_pr:.3f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Legit', 'Fraud']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluation Discussion\n",
        "\n",
        "### Assumptions\n",
        "- Historical fraud patterns remain stable\n",
        "- Fraudsters don't adapt faster than retraining cycle\n",
        "- On-chain data is ground truth\n",
        "\n",
        "### Potential Biases\n",
        "- **Geographic bias**: Model trained on US/EU events\n",
        "- **Temporal bias**: Holiday/event seasonality not fully captured\n",
        "- **Labeling bias**: Manual fraud labels may miss sophisticated attacks\n",
        "\n",
        "### Mitigation Strategies\n",
        "- Weekly drift monitoring\n",
        "- Quarterly model retraining\n",
        "- Human-in-the-loop review for borderline cases\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance visualization\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 5 Features:\")\n",
        "print(feature_importance.head())\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
